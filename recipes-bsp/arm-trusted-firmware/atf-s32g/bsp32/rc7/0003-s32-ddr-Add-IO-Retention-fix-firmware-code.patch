From 3f8d5d85ef52915c8f70c469d8434418fa53b2dd Mon Sep 17 00:00:00 2001
From: Andrei Cherechesu <andrei.cherechesu@nxp.com>
Date: Mon, 28 Feb 2022 14:51:16 +0200
Subject: [PATCH 3/5] s32: ddr: Add IO Retention fix firmware code

Added the DDR Firmware code which fixes the IO Retention issue.
Besides this issue, minor aestethical changes also occur due
to the code having been generated with a newer version of
DDR Tools software.

Issue: ALB-8540
Upstream-Status: Pending 

Signed-off-by: Andrei Cherechesu <andrei.cherechesu@nxp.com>
Signed-off-by: Zhantao Tang <zhantao.tang@windriver.com>
---
 drivers/nxp/s32/ddr/ddr_init.c          |  22 +-
 drivers/nxp/s32/ddr/ddr_lp_csr.c        |  18 +-
 drivers/nxp/s32/ddr/ddr_lp_mmio.c       |  45 ++-
 drivers/nxp/s32/ddr/ddr_utils_mmio.c    | 406 ++++++++++++++++++++++--
 include/drivers/nxp/s32/ddr/ddr_lp.h    |  18 +-
 include/drivers/nxp/s32/ddr/ddr_utils.h | 220 ++++++++++---
 6 files changed, 639 insertions(+), 90 deletions(-)

diff --git a/drivers/nxp/s32/ddr/ddr_init.c b/drivers/nxp/s32/ddr/ddr_init.c
index 27138b3bb..94b97b001 100644
--- a/drivers/nxp/s32/ddr/ddr_init.c
+++ b/drivers/nxp/s32/ddr/ddr_init.c
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020-2021 NXP
+ * Copyright 2020-2022 NXP
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
@@ -62,7 +62,8 @@ uint32_t ddr_init(void)
 
 		/* Execute post training setup */
 		ret = post_train_setup((uint8_t)(STORE_CSR_MASK |
-						 INIT_MEM_MASK));
+						 INIT_MEM_MASK |
+						 ADJUST_DDRC_MASK));
 		if (ret != NO_ERR)
 			return ret;
 	}
@@ -121,6 +122,15 @@ static uint32_t execute_training(const struct ddrss_config *config)
 	if (ret != NO_ERR)
 		return ret;
 
+	/* Read critical delay differences and training results */
+	mmio_write_32(MICROCONT_MUX_SEL, UNLOCK_CSR_ACCESS);
+	read_cdds();
+	if (config->memory_type == (uint8_t)LPDDR4)
+		read_vref_ca();
+	if (config->memory_type == (uint8_t)DDR3L)
+		compute_tphy_wrdata_delay();
+	mmio_write_32(MICROCONT_MUX_SEL, LOCK_CSR_ACCESS);
+
 	/*
 	 * Check if 2d training images have been initialized before executing
 	 * the second training stage.
@@ -153,6 +163,14 @@ static uint32_t execute_training(const struct ddrss_config *config)
 		ret = wait_firmware_execution();
 		if (ret != NO_ERR)
 			return ret;
+
+		/* Read 2D training results */
+		if (config->memory_type == (uint8_t)LPDDR4) {
+			mmio_write_32(MICROCONT_MUX_SEL, UNLOCK_CSR_ACCESS);
+			read_vref_dq();
+			compute_tphy_wrdata_delay();
+			mmio_write_32(MICROCONT_MUX_SEL, LOCK_CSR_ACCESS);
+		}
 	}
 
 	mmio_write_32(MICROCONT_MUX_SEL, UNLOCK_CSR_ACCESS);
diff --git a/drivers/nxp/s32/ddr/ddr_lp_csr.c b/drivers/nxp/s32/ddr/ddr_lp_csr.c
index 0d8540060..a49a17c0e 100644
--- a/drivers/nxp/s32/ddr/ddr_lp_csr.c
+++ b/drivers/nxp/s32/ddr/ddr_lp_csr.c
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 NXP
+ * Copyright 2021-2022 NXP
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
@@ -47,6 +47,12 @@ const uint32_t csr_to_store[] = {
 	0x000023f0,
 	0x000043f0,
 	0x000063f0,
+	0x000083f0,
+	0x0000a3f0,
+	0x0000c3f0,
+	0x0000e3f0,
+	0x000103f0,
+	0x000123f0,
 	0x000146b0,
 	0x000166b0,
 	0x000186b0,
@@ -369,3 +375,13 @@ const uint32_t csr_to_store[] = {
 };
 
 size_t csr_to_store_size = ARRAY_SIZE(csr_to_store);
+
+const uint32_t ddrc_to_store[] = {
+	OFFSET_DDRC_DRAMTMG2,
+	OFFSET_DDRC_RANKCTL,
+	OFFSET_DDRC_INIT6,
+	OFFSET_DDRC_INIT7,
+	OFFSET_DDRC_DFITMG1
+};
+
+size_t ddrc_to_store_size = ARRAY_SIZE(ddrc_to_store);
diff --git a/drivers/nxp/s32/ddr/ddr_lp_mmio.c b/drivers/nxp/s32/ddr/ddr_lp_mmio.c
index 07afc542e..de0defac4 100644
--- a/drivers/nxp/s32/ddr/ddr_lp_mmio.c
+++ b/drivers/nxp/s32/ddr/ddr_lp_mmio.c
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 NXP
+ * Copyright 2021-2022 NXP
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
@@ -32,6 +32,9 @@
 #include <ddr/ddr_init.h>
 #include <lib/mmio.h>
 
+static void load_csr(uintptr_t load_from);
+static void load_ddrc_regs(uintptr_t load_from);
+
 /* Store Configuration Status Registers. */
 void store_csr(uintptr_t store_at)
 {
@@ -53,7 +56,7 @@ void store_csr(uintptr_t store_at)
 }
 
 /* Load Configuration Status Registers. */
-void load_csr(uintptr_t load_from)
+static void load_csr(uintptr_t load_from)
 {
 	size_t i;
 	uint16_t csr;
@@ -66,6 +69,40 @@ void load_csr(uintptr_t load_from)
 	}
 }
 
+/* Store DDRC registers which have been updated post-training. */
+void store_ddrc_regs(uintptr_t store_at)
+{
+	size_t i;
+	uint32_t value;
+	uintptr_t current_addr = store_at;
+	/* DDRC registers are stored right after the CSRs */
+	current_addr += sizeof(uint16_t) * csr_to_store_size;
+	current_addr += sizeof(uint32_t) - (current_addr % sizeof(uint32_t));
+
+	for (i = 0; i < ddrc_to_store_size; i++) {
+		value = mmio_read_32((DDRC_BASE_ADDR + ddrc_to_store[i]));
+		mmio_write_32(current_addr, value);
+		current_addr += sizeof(uint32_t);
+	}
+}
+
+/* Load DDRC registers. */
+static void load_ddrc_regs(uintptr_t load_from)
+{
+	size_t i;
+	uint32_t value;
+	uintptr_t current_addr = load_from;
+	/* DDRC registers are stored right after the CSRs */
+	current_addr += sizeof(uint16_t) * csr_to_store_size;
+	current_addr += sizeof(uint32_t) - (current_addr % sizeof(uint32_t));
+
+	for (i = 0; i < ddrc_to_store_size; i++) {
+		value = mmio_read_32(current_addr);
+		mmio_write_32((DDRC_BASE_ADDR + ddrc_to_store[i]), value);
+		current_addr += sizeof(uint32_t);
+	}
+}
+
 /* Transition the DDR SubSystem from normal mode to retention mode. */
 void ddrss_to_io_retention_mode(void)
 {
@@ -160,6 +197,7 @@ uint32_t ddrss_to_normal_mode(uintptr_t csr_array)
 	uint32_t pwrctl, init0, ret;
 
 	ret = load_register_cfg(ddrc_cfg_size, ddrc_cfg);
+	load_ddrc_regs(csr_array);
 	if (ret != NO_ERR)
 		return ret;
 
@@ -202,5 +240,6 @@ uint32_t ddrss_to_normal_mode(uintptr_t csr_array)
 
 	mmio_write_32(MICROCONT_MUX_SEL, LOCK_CSR_ACCESS);
 
-	return post_train_setup(STORE_CSR_DISABLED | INIT_MEM_DISABLED);
+	return post_train_setup(STORE_CSR_DISABLED | INIT_MEM_DISABLED |
+				ADJUST_DDRC_DISABLED);
 }
diff --git a/drivers/nxp/s32/ddr/ddr_utils_mmio.c b/drivers/nxp/s32/ddr/ddr_utils_mmio.c
index e3f316145..6978abf25 100644
--- a/drivers/nxp/s32/ddr/ddr_utils_mmio.c
+++ b/drivers/nxp/s32/ddr/ddr_utils_mmio.c
@@ -1,5 +1,5 @@
 /*
- * Copyright 2020-2021 NXP
+ * Copyright 2020-2022 NXP
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
@@ -34,6 +34,8 @@
 #ifdef STORE_CSR_ENABLE
 /* Store Configuration Status Registers. */
 void store_csr(uintptr_t store_at);
+/* Store DDRC registers which have been updated post-training. */
+void store_ddrc_regs(uintptr_t store_at);
 #endif
 
 static uint32_t enable_axi_ports(void);
@@ -41,9 +43,23 @@ static uint32_t get_mail(uint32_t *mail);
 static uint32_t ack_mail(void);
 static uint32_t init_memory_ecc_scrubber(void);
 static void sel_clk_src(uint32_t clk_src, bool *already_set);
+static uint8_t get_max_cdd(const uint32_t cdd_addr[], size_t size);
+static uint16_t get_max_delay(const uint32_t delay_addr[], size_t size);
+static uint8_t get_avg_vref(const uint32_t vref_addr[], size_t size);
+static uint32_t adjust_ddrc_config(void);
+static bool is_lpddr4(void);
+
 
 #if (ERRATA_S32_050543 == 1)
 uint8_t polling_needed = 2;
+#endif
+
+static struct space_timing_params tr_res = {
+		.cdd = {.rr = 0, .rw = 0, .wr = 0, .ww = 0},
+		.vref_ca = 0,
+		.vref_dq = 0,
+		.tphy_wrdata_delay = 0
+};
 
 /* Modify bitfield value with delta, given bitfield position and mask */
 bool update_bf(uint32_t *v, uint8_t pos, uint32_t mask, int32_t delta)
@@ -59,7 +75,6 @@ bool update_bf(uint32_t *v, uint8_t pos, uint32_t mask, int32_t delta)
 
 	return ret;
 }
-#endif
 
 /*
  * Set the ddr clock source, FIRC or DDR_PLL_PHI0.
@@ -135,8 +150,7 @@ uint32_t set_axi_parity(void)
 	mmio_write_32(DDR_SS_REG, tmp32 | DDR_SS_AXI_PARITY_TYPE_MASK);
 
 	/* For LPDDR4 Set DFI1_ENABLED to 0x1 */
-	tmp32 = mmio_read_32(DDRC_BASE_ADDR);
-	if ((tmp32 & MSTR_LPDDR4_MASK) == MSTR_LPDDR4_VAL) {
+	if (is_lpddr4()) {
 		tmp32 = mmio_read_32(DDR_SS_REG);
 		mmio_write_32(DDR_SS_REG, tmp32 | DDR_SS_DFI_1_ENABLED);
 	}
@@ -281,6 +295,18 @@ uint32_t post_train_setup(uint8_t options)
 	mmio_write_32(DDRC_BASE_ADDR + OFFSET_DDRC_DFIMISC,
 		      (~DFIMISC_DFI_INIT_START_MASK) & tmp32);
 
+	if ((options & ADJUST_DDRC_MASK) != ADJUST_DDRC_DISABLED) {
+		/* Overwrite DDRC register based on post training_results */
+		ret = adjust_ddrc_config();
+		if (ret != NO_ERR)
+			return ret;
+	}
+
+#ifdef STORE_CSR_ENABLE
+	if ((options & STORE_CSR_MASK) != STORE_CSR_DISABLED)
+		store_ddrc_regs(RETENTION_ADDR);
+#endif
+
 	/* Set dfi_complete_en to 1 */
 	tmp32 = mmio_read_32(DDRC_BASE_ADDR + OFFSET_DDRC_DFIMISC);
 	mmio_write_32(DDRC_BASE_ADDR + OFFSET_DDRC_DFIMISC,
@@ -316,37 +342,40 @@ uint32_t post_train_setup(uint8_t options)
 	if (((tmp32 & ECCCFG0_ECC_MODE_MASK) > ECCCFG0_ECC_DISABLED) &&
 	    ((options & INIT_MEM_MASK) != INIT_MEM_DISABLED)) {
 		ret = init_memory_ecc_scrubber();
+		if (ret != NO_ERR)
+			return ret;
 	}
 
-	if (ret == NO_ERR) {
-		/* Enable power down: PWRCTL.powerdown_en = 1 */
-		tmp32 = mmio_read_32(DDRC_BASE_ADDR + OFFSET_DDRC_PWRCTL);
-		mmio_write_32(DDRC_BASE_ADDR + OFFSET_DDRC_PWRCTL,
-			      PWRCTL_POWER_DOWN_ENABLE_MASK | tmp32);
-
-		/* Enable self-refresh: PWRCTL.selfref_en = 1 */
-		tmp32 = mmio_read_32(DDRC_BASE_ADDR + OFFSET_DDRC_PWRCTL);
-		mmio_write_32(DDRC_BASE_ADDR + OFFSET_DDRC_PWRCTL,
-			      PWRCTL_SELF_REFRESH_ENABLE_MASK | tmp32);
-
-		/*
-		 * Enable assertion of dfi_dram_clk_disable:
-		 * PWRTL.en_dfi_dram_clk_disable = 1
-		 */
-		tmp32 = mmio_read_32(DDRC_BASE_ADDR + OFFSET_DDRC_PWRCTL);
-		mmio_write_32(DDRC_BASE_ADDR + OFFSET_DDRC_PWRCTL,
-			      PWRCTL_EN_DFI_DRAM_CLOCK_DIS_MASK | tmp32);
+	/* Enable power down: PWRCTL.powerdown_en = 1 */
+	tmp32 = mmio_read_32(DDRC_BASE_ADDR + OFFSET_DDRC_PWRCTL);
+	mmio_write_32(DDRC_BASE_ADDR + OFFSET_DDRC_PWRCTL,
+		      PWRCTL_POWER_DOWN_ENABLE_MASK | tmp32);
+
+	/* Enable self-refresh: PWRCTL.selfref_en = 1 */
+	tmp32 = mmio_read_32(DDRC_BASE_ADDR + OFFSET_DDRC_PWRCTL);
+	mmio_write_32(DDRC_BASE_ADDR + OFFSET_DDRC_PWRCTL,
+		      PWRCTL_SELF_REFRESH_ENABLE_MASK | tmp32);
+
+	/*
+	 * Enable assertion of dfi_dram_clk_disable:
+	 * PWRTL.en_dfi_dram_clk_disable = 1
+	 */
+	tmp32 = mmio_read_32(DDRC_BASE_ADDR + OFFSET_DDRC_PWRCTL);
+	mmio_write_32(DDRC_BASE_ADDR + OFFSET_DDRC_PWRCTL,
+		      PWRCTL_EN_DFI_DRAM_CLOCK_DIS_MASK | tmp32);
 
 #if (ERRATA_S32_050543 == 1)
-		ret |= enable_derating_temp_errata();
+	ret = enable_derating_temp_errata();
+	if (ret != NO_ERR)
+		return ret;
 #endif
 
-		/*
-		 * Each platform has a different number of AXI ports so this
-		 * method should be implemented in hardware specific source
-		 */
-		ret |= enable_axi_ports();
-	}
+	/*
+	 * Each platform has a different number of AXI ports so this
+	 * method should be implemented in hardware specific source
+	 */
+	ret = enable_axi_ports();
+
 	return ret;
 }
 
@@ -622,6 +651,323 @@ uint32_t write_lpddr4_mr(uint8_t mr_index, uint8_t mr_data)
 	return NO_ERR;
 }
 
+/* Read Critical Delay Differences from message block and store max values */
+void read_cdds(void)
+{
+	uint8_t cdd_rr = 0, cdd_ww = 0, cdd_wr = 0, cdd_rw = 0;
+	uint32_t mstr;
+	const uint32_t rank0_rw_addr[] = {CDD_CHA_RW_0_0, CDD_CHB_RW_0_0};
+	const uint32_t rank0_wr_addr[] = {CDD_CHA_WR_0_0, CDD_CHB_WR_0_0};
+
+	/* Max CDD values for single-rank */
+	tr_res.cdd.rr = cdd_rr;
+	tr_res.cdd.ww = cdd_ww;
+	tr_res.cdd.rw = is_lpddr4() ?
+			get_max_cdd(rank0_rw_addr, ARRAY_SIZE(rank0_rw_addr)) :
+			mmio_read_8(CDD_CHA_RW_0_0_DDR3);
+	tr_res.cdd.wr = is_lpddr4() ?
+			get_max_cdd(rank0_wr_addr, ARRAY_SIZE(rank0_wr_addr)) :
+			mmio_read_8(CDD_CHA_WR_0_0_DDR3);
+
+	/* Check MSTR.active_ranks to identify multi-rank configurations */
+	mstr = mmio_read_32(DDRC_BASE_ADDR);
+	if ((mstr & MSTR_ACT_RANKS_MASK) == MSTR_DUAL_RANK_VAL) {
+		/* Compute max CDDs for both ranks depending on memory type */
+		if (is_lpddr4()) {
+			const uint32_t rr_addr[] = {
+					CDD_CHA_RR_1_0, CDD_CHA_RR_0_1,
+					CDD_CHB_RR_1_0, CDD_CHB_RR_0_1};
+			const uint32_t ww_addr[] = {
+					CDD_CHA_WW_1_0, CDD_CHA_WW_0_1,
+					CDD_CHB_WW_1_0, CDD_CHB_WW_0_1};
+			const uint32_t rw_addr[] = {
+					CDD_CHA_RW_1_1, CDD_CHA_RW_1_0,
+					CDD_CHA_RW_0_1, CDD_CHB_RW_1_1,
+					CDD_CHB_RW_1_0, CDD_CHB_RW_0_1};
+			const uint32_t wr_addr[] = {
+					CDD_CHA_WR_1_1, CDD_CHA_WR_1_0,
+					CDD_CHA_WR_0_1, CDD_CHB_WR_1_1,
+					CDD_CHB_WR_1_0, CDD_CHB_WR_0_1};
+
+			cdd_rr = get_max_cdd(rr_addr, ARRAY_SIZE(rr_addr));
+			cdd_rw = get_max_cdd(rw_addr, ARRAY_SIZE(rw_addr));
+			cdd_wr = get_max_cdd(wr_addr, ARRAY_SIZE(wr_addr));
+			cdd_ww = get_max_cdd(ww_addr, ARRAY_SIZE(ww_addr));
+		} else {
+			const uint32_t rr_addr[] = {CDD_CHA_RR_1_0_DDR3,
+						    CDD_CHA_RR_0_1_DDR3};
+			const uint32_t ww_addr[] = {CDD_CHA_WW_1_0_DDR3,
+						    CDD_CHA_WW_0_1_DDR3};
+			const uint32_t rw_addr[] = {CDD_CHA_RW_1_1_DDR3,
+						    CDD_CHA_RW_1_0_DDR3,
+						    CDD_CHA_RW_0_1_DDR3};
+			const uint32_t wr_addr[] = {CDD_CHA_WR_1_1_DDR3,
+						    CDD_CHA_WR_1_0_DDR3,
+						    CDD_CHA_WR_0_1_DDR3};
+
+			cdd_rr = get_max_cdd(rr_addr, ARRAY_SIZE(rr_addr));
+			cdd_rw = get_max_cdd(rw_addr, ARRAY_SIZE(rw_addr));
+			cdd_wr = get_max_cdd(wr_addr, ARRAY_SIZE(wr_addr));
+			cdd_ww = get_max_cdd(ww_addr, ARRAY_SIZE(ww_addr));
+		}
+
+		/* Update max CDD values if needed */
+		if (cdd_rr > tr_res.cdd.rr)
+			tr_res.cdd.rr = cdd_rr;
+		if (cdd_rw > tr_res.cdd.rw)
+			tr_res.cdd.rw = cdd_rw;
+		if (cdd_wr > tr_res.cdd.wr)
+			tr_res.cdd.wr = cdd_wr;
+		if (cdd_ww > tr_res.cdd.ww)
+			tr_res.cdd.ww = cdd_ww;
+	}
+}
+
+/* Read trained VrefCA from message block and store average value */
+void read_vref_ca(void)
+{
+	uint32_t mstr;
+	const uint32_t rank0_vref_addr[] = {VREF_CA_A0, VREF_CA_B0};
+	const uint32_t rank01_vref_addr[] = {VREF_CA_A0, VREF_CA_A1,
+					     VREF_CA_B0, VREF_CA_B1};
+
+	/* Check MSTR.active_ranks to identify multi-rank configurations */
+	mstr = mmio_read_32(DDRC_BASE_ADDR);
+	if ((mstr & MSTR_ACT_RANKS_MASK) == MSTR_DUAL_RANK_VAL)
+		tr_res.vref_ca = get_avg_vref(rank01_vref_addr,
+					      ARRAY_SIZE(rank01_vref_addr));
+	else
+		tr_res.vref_ca = get_avg_vref(rank0_vref_addr,
+					      ARRAY_SIZE(rank0_vref_addr));
+}
+
+/* Read trained VrefDQ from message block and store average value*/
+void read_vref_dq(void)
+{
+	uint32_t mstr;
+	const uint32_t rank0_vref_addr[] = {VREF_DQ_A0, VREF_DQ_B0};
+	const uint32_t rank01_vref_addr[] = {VREF_DQ_A0, VREF_DQ_A1,
+					     VREF_DQ_B0, VREF_DQ_B1};
+
+	/* Check MSTR.active_ranks to identify multi-rank configurations */
+	mstr = mmio_read_32(DDRC_BASE_ADDR);
+	if ((mstr & MSTR_ACT_RANKS_MASK) == MSTR_DUAL_RANK_VAL)
+		tr_res.vref_dq = get_avg_vref(rank01_vref_addr,
+					      ARRAY_SIZE(rank01_vref_addr));
+	else
+		tr_res.vref_dq = get_avg_vref(rank0_vref_addr,
+					      ARRAY_SIZE(rank0_vref_addr));
+}
+
+/* Calculate DFITMG1.dfi_t_wrdata_delay */
+void compute_tphy_wrdata_delay(void)
+{
+	const uint32_t single_rank_dly_addr[] = {
+			DBYTE0_TXDQSDLYTG0_U0, DBYTE0_TXDQSDLYTG0_U1,
+			DBYTE1_TXDQSDLYTG0_U0, DBYTE1_TXDQSDLYTG0_U1,
+			DBYTE2_TXDQSDLYTG0_U0, DBYTE2_TXDQSDLYTG0_U1,
+			DBYTE3_TXDQSDLYTG0_U0, DBYTE3_TXDQSDLYTG0_U1};
+
+	const uint32_t dual_rank_dly_addr[] = {
+			DBYTE0_TXDQSDLYTG1_U0, DBYTE0_TXDQSDLYTG1_U1,
+			DBYTE1_TXDQSDLYTG1_U0, DBYTE1_TXDQSDLYTG1_U1,
+			DBYTE2_TXDQSDLYTG1_U0, DBYTE2_TXDQSDLYTG1_U1,
+			DBYTE3_TXDQSDLYTG1_U0, DBYTE3_TXDQSDLYTG1_U1};
+
+	uint16_t tx_dqsdly, tx_dqsdly_tg1, tctrl_delay, burst_length,
+		 wrdata_use_dfi_phy_clk;
+	uint32_t mstr, dfitmg0;
+
+	/* Compute max tx_dqdqsdly for rank 0 */
+	tx_dqsdly = get_max_delay(single_rank_dly_addr,
+				  ARRAY_SIZE(single_rank_dly_addr));
+
+	/* Check MSTR.active_ranks to identify multi-rank configurations */
+	mstr = mmio_read_32(DDRC_BASE_ADDR);
+	if ((mstr & MSTR_ACT_RANKS_MASK) == MSTR_DUAL_RANK_VAL) {
+		/* Compute max tx_dqdqsdly for rank 1 */
+		tx_dqsdly_tg1 = get_max_delay(dual_rank_dly_addr,
+					      ARRAY_SIZE(dual_rank_dly_addr));
+		if (tx_dqsdly_tg1 > tx_dqsdly)
+			tx_dqsdly = tx_dqsdly_tg1;
+	}
+
+	/* Extract coarse delay value + 1 for fine delay */
+	tx_dqsdly = (tx_dqsdly >> TXDQDLY_COARSE) + 1U;
+
+	/* Compute tctrl_delay */
+	tctrl_delay = (uint16_t)((mmio_read_16(ARDPTR_INITVAL_ADDR) / 2U) +
+				 (DDRPHY_PIPE_DFI_MISC * 2U) + 3U);
+
+	burst_length = (uint16_t)(mstr >> MSTR_BURST_RDWR_POS) &
+				  MSTR_BURST_RDWR_MASK;
+	dfitmg0 = mmio_read_16(DDRC_BASE_ADDR + OFFSET_DDRC_DFITMG0);
+	wrdata_use_dfi_phy_clk = (uint16_t)(dfitmg0 >> DFITMG0_PHY_CLK_POS) &
+					    DFITMG0_PHY_CLK_MASK;
+
+	/* Program */
+	tr_res.tphy_wrdata_delay = tctrl_delay + 6U + burst_length +
+				   wrdata_use_dfi_phy_clk + tx_dqsdly;
+	tr_res.tphy_wrdata_delay = (tr_res.tphy_wrdata_delay / 2U) +
+				   (tr_res.tphy_wrdata_delay % 2U);
+}
+
+/* Re-program some of the DDRC registers based on post-training results. */
+static uint32_t adjust_ddrc_config(void)
+{
+	uint32_t tmp32;
+	uint8_t rd_gap, wr_gap, rd_gap_new, wr_gap_new, delta, min;
+	uint8_t rd_gap_lp4 = 4, rd_gap_ddr3 = 2, wr_gap_lp4 = 5;
+	uint8_t wr_gap_ddr3 = 3, min_lp4 = 7, min_ddr3 = 0xe, max = 0xf;
+	uint32_t ret = NO_ERR;
+
+	/* DRAMTMG2.rd2wr & DRAMTMG2.wr2rd */
+	tmp32 = mmio_read_32(DDRC_BASE_ADDR + OFFSET_DDRC_DRAMTMG2);
+	delta = (uint8_t)((tr_res.cdd.rw + (tr_res.cdd.rw % 2U)) / 2U);
+	if (!update_bf(&tmp32, DRAMTMG2_RD_WR_POS, DRAMTMG2_RD_WR_MASK,
+		       (int32_t)delta))
+		return BITFIELD_EXCEEDED;
+	delta = (uint8_t)((tr_res.cdd.ww + (tr_res.cdd.ww % 2U)) / 2U);
+	if (!update_bf(&tmp32, DRAMTMG2_WR_RD_POS, DRAMTMG2_WR_RD_MASK,
+		       (int32_t)delta))
+		return BITFIELD_EXCEEDED;
+	mmio_write_32(DDRC_BASE_ADDR + OFFSET_DDRC_DRAMTMG2, tmp32);
+
+	/* For LPDDR4 overwrite INIT6 and INIT7 DDRC registers */
+	if (is_lpddr4()) {
+		/* INIT6.mr5 */
+		tmp32 = mmio_read_32(DDRC_BASE_ADDR + OFFSET_DDRC_INIT6);
+		tmp32 = (tmp32 & ~(INIT6_MR5_MASK)) | tr_res.vref_ca;
+		mmio_write_32(DDRC_BASE_ADDR + OFFSET_DDRC_INIT6, tmp32);
+
+		/* INIT7.mr6 */
+		tmp32 = mmio_read_32(DDRC_BASE_ADDR + OFFSET_DDRC_INIT7);
+		tmp32 = (tmp32 & ~(INIT7_MR6_MASK)) | tr_res.vref_dq;
+		mmio_write_32(DDRC_BASE_ADDR + OFFSET_DDRC_INIT7, tmp32);
+	}
+
+	/* DFITMG1.dfi_t_wrdata_delay */
+	tmp32 = mmio_read_32(DDRC_BASE_ADDR + OFFSET_DDRC_DFITMG1);
+	tmp32 &= ~(DFITMG1_WRDATA_DELAY_MASK << DFITMG1_WRDATA_DELAY_POS);
+	tmp32 |= (((uint32_t)tr_res.tphy_wrdata_delay) <<
+		  DFITMG1_WRDATA_DELAY_POS);
+	mmio_write_32(DDRC_BASE_ADDR + OFFSET_DDRC_DFITMG1, tmp32);
+
+	/* For multi-rank systems */
+	tmp32 = mmio_read_32(DDRC_BASE_ADDR);
+	if ((tmp32 & MSTR_ACT_RANKS_MASK) == MSTR_DUAL_RANK_VAL) {
+		uint8_t rd_gap_ct = is_lpddr4() ? rd_gap_lp4 : rd_gap_ddr3;
+		uint8_t wr_gap_ct = is_lpddr4() ? wr_gap_lp4 : wr_gap_ddr3;
+
+		min = is_lpddr4() ? min_lp4 : min_ddr3;
+		tmp32 = mmio_read_32(DDRC_BASE_ADDR + OFFSET_DDRC_RANKCTL);
+
+		/* RANKCTL.diff_rank_rd_gap */
+		rd_gap = (uint8_t)((tmp32 >> RANKCTL_RD_GAP_POS) &
+				   RANKCTL_RD_GAP_MASK);
+		rd_gap_new = (uint8_t)((rd_gap_ct + tr_res.cdd.rr +
+				       (tr_res.cdd.rr % 2U)) / 2U);
+
+		/* ensure min and max of rd_gap field */
+		rd_gap_new = (rd_gap_new < min) ? min : ((rd_gap_new > max) ?
+				max : rd_gap_new);
+		if (rd_gap_new > rd_gap) {
+			delta = (uint8_t)(rd_gap_new - rd_gap);
+			if (!update_bf(&tmp32, RANKCTL_RD_GAP_POS,
+				       RANKCTL_RD_GAP_MASK, (int32_t)delta))
+				return BITFIELD_EXCEEDED;
+		}
+
+		/* RANKCTL.diff_rank_wr_gap */
+		wr_gap = (uint8_t)((tmp32 >> RANKCTL_WR_GAP_POS) &
+				   RANKCTL_WR_GAP_MASK);
+		wr_gap_new = (uint8_t)((wr_gap_ct + tr_res.cdd.ww +
+				       (tr_res.cdd.ww % 2U)) / 2U);
+
+		/* ensure min and max of wr_gap field */
+		wr_gap_new = (wr_gap_new < min) ? min : ((wr_gap_new > max) ?
+				max : wr_gap_new);
+		if (wr_gap_new > wr_gap) {
+			delta = (uint8_t)(wr_gap_new - wr_gap);
+			if (!update_bf(&tmp32, RANKCTL_WR_GAP_POS,
+				       RANKCTL_WR_GAP_MASK, (int32_t)delta))
+				return BITFIELD_EXCEEDED;
+		}
+
+		if (rd_gap_new > rd_gap || wr_gap_new > wr_gap)
+			mmio_write_32(DDRC_BASE_ADDR + OFFSET_DDRC_RANKCTL,
+				      tmp32);
+	}
+
+	return ret;
+}
+
+/* Check if memory type is LPDDR4 using MSTR register */
+static bool is_lpddr4(void)
+{
+	uint32_t mstr;
+
+	mstr = mmio_read_32(DDRC_BASE_ADDR);
+	return ((mstr & MSTR_DRAM_MASK) == MSTR_LPDDR4_VAL);
+}
+
+/*
+ * Get maximum critical delay difference value.
+ * @param cdd_addr[] - list of CDD memory addresses
+ * @param size - number of CDDs to be read
+ * @return max CDD value
+ */
+static uint8_t get_max_cdd(const uint32_t cdd_addr[], size_t size)
+{
+	uint8_t cdd, max = 0;
+	int8_t signed_cdd;
+	size_t i;
+
+	for (i = 0; i < size; i++) {
+		/* CDD has type int8_t - read as unsigned and cast to signed */
+		signed_cdd = (int8_t)(mmio_read_8(cdd_addr[i]));
+		/* We need to use absolute value */
+		cdd = (uint8_t)((signed_cdd >= 0) ? signed_cdd : -signed_cdd);
+		max = (cdd > max) ? cdd : max;
+	}
+	return max;
+}
+
+/*
+ * Get maximum delay value.
+ * @param delay_addr[] - list of CDD memory addresses
+ * @param size - number of values to be read
+ * @return max delay value
+ */
+static uint16_t get_max_delay(const uint32_t delay_addr[], size_t size)
+{
+	uint16_t value, max = 0;
+	size_t i;
+
+	for (i = 0; i < size; i++) {
+		value = mmio_read_16(delay_addr[i]);
+		max = (value > max) ? value : max;
+	}
+	return max;
+}
+
+/*
+ * Compute average vref value.
+ * @param vref_addr[] - list of vref memory addresses
+ * @param size - number of values to be read
+ * @return average vref value
+ */
+static uint8_t get_avg_vref(const uint32_t vref_addr[], size_t size)
+{
+	uint32_t sum = 0;
+	size_t i;
+
+	for (i = 0; i < size; i++)
+		sum += mmio_read_8(vref_addr[i]);
+
+	return (uint8_t)(sum / size);
+}
+
 #if (ERRATA_S32_050543 == 1)
 /* Read Temperature Update Flag from lpddr4 MR4 register. */
 uint8_t read_tuf(void)
@@ -751,4 +1097,4 @@ uint32_t enable_derating_temp_errata(void)
 
 	return NO_ERR;
 }
-#endif
\ No newline at end of file
+#endif
diff --git a/include/drivers/nxp/s32/ddr/ddr_lp.h b/include/drivers/nxp/s32/ddr/ddr_lp.h
index 2a608fb50..1bdf9edb1 100644
--- a/include/drivers/nxp/s32/ddr/ddr_lp.h
+++ b/include/drivers/nxp/s32/ddr/ddr_lp.h
@@ -1,5 +1,5 @@
 /*
- * Copyright 2021 NXP
+ * Copyright 2021-2022 NXP
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
@@ -36,24 +36,26 @@
 #define DDRSS_BASE_ADDR                 0x40380000U
 
 #define DDR_GPR_OFFSET                  (0x4007c600U)
-#define DDR_CONFIG_0_REG                (uint32_t)(DDR_GPR_OFFSET + 0x00U)
-#define DDR_RET_CONTROL_REG             (uint32_t)(DDR_GPR_OFFSET + 0x1cU)
+#define DDR_CONFIG_0_REG                ((uint32_t)(DDR_GPR_OFFSET + 0x00U))
+#define DDR_RET_CONTROL_REG             ((uint32_t)(DDR_GPR_OFFSET + 0x1cU))
 #define DDR_RET_CONTROL_MASK            SHIFT_BIT(0)
 #define DDR_CONFIG_0_MEM_RET            SHIFT_BIT(14)
 
 #define DFI_FREQUENCY(f)                ((f) << 8)
-#define SELFREF_STATE_SRPD              ((uint32_t)0x2U << 8)
+#define SELFREF_STATE_SRPD              (((uint32_t)0x2U) << 8)
 #define SELFREF_STATE_MASK              (SHIFT_BIT(8) | SHIFT_BIT(9))
-#define SELFREF_TYPE_NOT_AUTO_SR_CTRL   ((uint32_t)0x2U << 4)
+#define SELFREF_TYPE_NOT_AUTO_SR_CTRL   (((uint32_t)0x2U) << 4)
 #define OPERATING_MODE_SELF_REFRESH     0x3U
 
 #define DISABLE_AXI_PORT                0x0
 #define DFIMISC_TRANSITION_PHY_TO_LP3   0x0
-#define DFIMISC_LP3_PHY_STATE           (uint32_t)0x1fU
+#define DFIMISC_LP3_PHY_STATE           ((uint32_t)0x1fU)
 #define	STAT_RESET_VALUE                0x0U
 
 extern const uint32_t csr_to_store[];
+extern const uint32_t ddrc_to_store[];
 extern size_t csr_to_store_size;
+extern size_t ddrc_to_store_size;
 
 /* Transition the DDR SubSystem from normal mode to retention mode. */
 void ddrss_to_io_retention_mode(void);
@@ -64,7 +66,7 @@ uint32_t ddrss_to_normal_mode(uintptr_t csr_array);
 /* Store Configuration Status Registers. */
 void store_csr(uintptr_t store_at);
 
-/* Load Configuration Status Registers. */
-void load_csr(uintptr_t load_from);
+/* Store DDRC registers which have been updated post-training. */
+void store_ddrc_regs(uintptr_t store_at);
 
 #endif /* LP_DDR_LP_H_ */
diff --git a/include/drivers/nxp/s32/ddr/ddr_utils.h b/include/drivers/nxp/s32/ddr/ddr_utils.h
index 7300aa02b..6b3d3c275 100644
--- a/include/drivers/nxp/s32/ddr/ddr_utils.h
+++ b/include/drivers/nxp/s32/ddr/ddr_utils.h
@@ -51,43 +51,69 @@
 #define BITFIELD_EXCEEDED   0x00000004U
 
 /* DDRC related */
-#define DDRC_BASE_ADDR                   (uint32_t)0x403C0000U
-#define OFFSET_DDRC_SWCTL                (uint32_t)0x320U
-#define OFFSET_DDRC_DFIMISC              (uint32_t)0x1b0U
-#define OFFSET_DDRC_DFISTAT              (uint32_t)0x1bcU
-#define OFFSET_DDRC_PWRCTL               (uint32_t)0x30U
-#define OFFSET_DDRC_SWSTAT               (uint32_t)0x324U
-#define OFFSET_DDRC_STAT                 (uint32_t)0x04U
-#define OFFSET_DDRC_DBG1                 (uint32_t)0x304U
-#define OFFSET_DDRC_ECCCFG0              (uint32_t)0x70U
-#define OFFSET_DDRC_ECCCFG1              (uint32_t)0x74U
-#define OFFSET_DDRC_SBRCTL               (uint32_t)0xf24U
-#define OFFSET_DDRC_SBRSTAT              (uint32_t)0xf28U
-#define OFFSET_DDRC_SBRWDATA0            (uint32_t)0xf2cU
-#define OFFSET_DDRC_MRSTAT               (uint32_t)0x18U
-#define OFFSET_DDRC_MRCTRL0              (uint32_t)0x10U
-#define OFFSET_DDRC_MRCTRL1              (uint32_t)0x14U
+#define DDRC_BASE_ADDR                   ((uint32_t)0x403C0000U)
+#define OFFSET_DDRC_SWCTL                ((uint32_t)0x320U)
+#define OFFSET_DDRC_DFIMISC              ((uint32_t)0x1b0U)
+#define OFFSET_DDRC_DFISTAT              ((uint32_t)0x1bcU)
+#define OFFSET_DDRC_PWRCTL               ((uint32_t)0x30U)
+#define OFFSET_DDRC_SWSTAT               ((uint32_t)0x324U)
+#define OFFSET_DDRC_STAT                 ((uint32_t)0x04U)
+#define OFFSET_DDRC_DBG1                 ((uint32_t)0x304U)
+#define OFFSET_DDRC_ECCCFG0              ((uint32_t)0x70U)
+#define OFFSET_DDRC_ECCCFG1              ((uint32_t)0x74U)
+#define OFFSET_DDRC_SBRCTL               ((uint32_t)0xf24U)
+#define OFFSET_DDRC_SBRSTAT              ((uint32_t)0xf28U)
+#define OFFSET_DDRC_SBRWDATA0            ((uint32_t)0xf2cU)
+#define OFFSET_DDRC_MRSTAT               ((uint32_t)0x18U)
+#define OFFSET_DDRC_MRCTRL0              ((uint32_t)0x10U)
+#define OFFSET_DDRC_MRCTRL1              ((uint32_t)0x14U)
 
 #if (ERRATA_S32_050543 == 1)
-#define OFFSET_DDRC_DERATEEN             (uint32_t)0x20U
-#define OFFSET_DDRC_RFSHTMG              (uint32_t)0x64U
-#define OFFSET_DDRC_DRAMTMG0             (uint32_t)0x100U
-#define OFFSET_DDRC_DRAMTMG1             (uint32_t)0x104U
-#define OFFSET_DDRC_DRAMTMG4             (uint32_t)0x110U
+#define OFFSET_DDRC_DERATEEN             ((uint32_t)0x20U)
+#define OFFSET_DDRC_RFSHTMG              ((uint32_t)0x64U)
+#define OFFSET_DDRC_DRAMTMG0             ((uint32_t)0x100U)
+#define OFFSET_DDRC_DRAMTMG1             ((uint32_t)0x104U)
+#define OFFSET_DDRC_DRAMTMG4             ((uint32_t)0x110U)
 #endif
 
+#define OFFSET_DDRC_DRAMTMG2             (uint32_t)0x108
+#define OFFSET_DDRC_INIT6                (uint32_t)0xe8
+#define OFFSET_DDRC_INIT7                (uint32_t)0xec
+#define OFFSET_DDRC_RANKCTL              (uint32_t)0xf4
+#define OFFSET_DDRC_DFITMG0              (uint32_t)0x190
+#define OFFSET_DDRC_DFITMG1              (uint32_t)0x194
+
 /* DDRC masks and values */
-#define MSTR_LPDDR4_MASK	0x20U
-#define MSTR_LPDDR4_VAL		0x20U
+#define MSTR_LPDDR4_VAL		((uint32_t)0x20)
 #define SWSTAT_SW_DONE		1U
 #define SWSTAT_SW_NOT_DONE	0U
 #define SWCTL_SWDONE_DONE	0x1
 #define SWCTL_SWDONE_ENABLE	0x0
 #define SWSTAT_SWDONE_ACK_MASK	0x1U
 
+#define MSTR_DRAM_MASK		((uint32_t)0x3f)
+#define MSTR_ACT_RANKS_MASK ((uint32_t)0x3000000)
+#define MSTR_DUAL_RANK_VAL  ((uint32_t)0x3000000)
+#define MSTR_BURST_RDWR_POS 16
+#define MSTR_BURST_RDWR_MASK ((uint16_t)0xf)
+#define DFITMG0_PHY_CLK_POS  15
+#define DFITMG0_PHY_CLK_MASK ((uint16_t)0x1)
+#define DRAMTMG2_RD_WR_POS  8
+#define DRAMTMG2_RD_WR_MASK 0x1f
+#define DRAMTMG2_WR_RD_POS  0
+#define DRAMTMG2_WR_RD_MASK 0x1f
+#define INIT6_MR5_MASK      0xffffU
+#define INIT7_MR6_MASK      0xffffU
+#define DFITMG1_WRDATA_DELAY_POS 16
+#define DFITMG1_WRDATA_DELAY_MASK ((uint32_t)0x1f)
+#define RANKCTL_RD_GAP_POS 4
+#define RANKCTL_RD_GAP_MASK ((uint32_t)0xf)
+#define RANKCTL_WR_GAP_POS 8
+#define RANKCTL_WR_GAP_MASK ((uint32_t)0xfU)
+
 #if (ERRATA_S32_050543 == 1)
 #define RFSHTMG_VAL_SHIFT           16
-#define RFSHTMG_VAL                 (uint32_t)0xfffU
+#define RFSHTMG_VAL                 ((uint32_t)0xfffU)
 #define RFSHTMG_MASK                (RFSHTMG_VAL << \
 	RFSHTMG_VAL_SHIFT)
 #define RFSHCTL3_UPDATE_SHIFT       1
@@ -158,14 +184,14 @@
 #define	ECCCFG0_ECC_DISABLED		0x0U
 #define	TRAINING_OK_MSG			0x07U
 #define	TRAINING_FAILED_MSG		0xFFU
-#define	ECCCFG1_REGION_PARITY_LOCKED	(uint32_t)0x1U
+#define	ECCCFG1_REGION_PARITY_LOCKED	((uint32_t)0x1U)
 #define	ECCCFG1_REGION_PARITY_LOCK_POS	4
-#define	SBRCTL_SCRUB_MODE_WRITE		(uint32_t)0x1U
+#define	SBRCTL_SCRUB_MODE_WRITE		((uint32_t)0x1U)
 #define	SBRCTL_SCRUB_MODE_POS		2
 
 #define	APBONLY_DCTWRITEPROT_ACK_EN              0
 #define	APBONLY_DCTWRITEPROT_ACK_DIS             1
-#define	SBRCTL_SCRUB_DURING_LOWPOWER_CONTINUED   (uint32_t)0x1U
+#define	SBRCTL_SCRUB_DURING_LOWPOWER_CONTINUED   ((uint32_t)0x1U)
 #define	SBRCTL_SCRUB_DURING_LOWPOWER_POS         1
 
 #define	SBRCTL_SCRUB_INTERVAL_FIELD     0x1FFFU
@@ -175,34 +201,35 @@
 #define	SBRSTAT_SCRUBBER_NOT_DONE       0x0U
 #define	SBRSTAT_SCRUBBER_BUSY_MASK      0x1U
 #define	SBRSTAT_SCRUBBER_NOT_BUSY       0x0U
-#define	SBRCTL_SCRUB_INTERVAL_VALUE_1   (uint32_t)0x1U
+#define	SBRCTL_SCRUB_INTERVAL_VALUE_1   ((uint32_t)0x1U)
 #define	MRR_0_DDR_SEL_REG_MASK          0x1U
 
 #define	MRSTAT_MR_BUSY                  0x1U
 #define	MRSTAT_MR_NOT_BUSY              0x0U
 #define	MRCTRL0_MR_TYPE_READ            0x1U
 #define	MRCTRL0_RANK_ACCESS_POS         4
-#define	MRCTRL0_RANK_ACCESS_FIELD       (uint32_t)0xfU
+#define	MRCTRL0_RANK_ACCESS_FIELD       ((uint32_t)0xfU)
 #define	MRCTRL0_RANK_0                  0x1U
-#define	MRCTRL1_MR_ADDRESS_FIELD        (uint32_t)0xffU
+#define	MRCTRL1_MR_ADDRESS_FIELD        ((uint32_t)0xffU)
 #define	MRCTRL1_MR_ADDRESS_POS          8
-#define	MRCTRL0_WR_ENGAGE               (uint32_t)0x1U
+#define	MRCTRL0_WR_ENGAGE               ((uint32_t)0x1U)
 #define	MRCTRL0_WR_ENGAGE_POS           31
-#define	MRCTRL1_MR_DATA_ADDRESS_FIELD   (uint32_t)0xffffU
+#define	MRCTRL1_MR_DATA_ADDRESS_FIELD   ((uint32_t)0xffffU)
 #define	MRCTRL1_MR_DATA_ADDRESS_POS     16
 #define STORE_CSR_DISABLED              0x0U
 #define INIT_MEM_DISABLED               0x0U
+#define ADJUST_DDRC_DISABLED            0x0U
 
 /* Performance monitoring registers */
-#define PERF_BASE_ADDR                   (uint32_t)0x403E0000U
-#define OFFSET_MRR_0_DATA_REG_ADDR       (uint32_t)0x40U
-#define OFFSET_MRR_1_DATA_REG_ADDR       (uint32_t)0x44U
+#define PERF_BASE_ADDR                   ((uint32_t)0x403E0000U)
+#define OFFSET_MRR_0_DATA_REG_ADDR       ((uint32_t)0x40U)
+#define OFFSET_MRR_1_DATA_REG_ADDR       ((uint32_t)0x44U)
 
 /* uMCTL2 Multi-Port Registers */
-#define DDRC_UMCTL2_MP_BASE_ADDR         (uint32_t)0x403C03F8U
-#define OFFSET_DDRC_PCTRL_0              (uint32_t)0x98U
-#define OFFSET_DDRC_PCTRL_1              (uint32_t)0x148U
-#define OFFSET_DDRC_PCTRL_2              (uint32_t)0x1f8U
+#define DDRC_UMCTL2_MP_BASE_ADDR         ((uint32_t)0x403C03F8U)
+#define OFFSET_DDRC_PCTRL_0              ((uint32_t)0x98U)
+#define OFFSET_DDRC_PCTRL_1              ((uint32_t)0x148U)
+#define OFFSET_DDRC_PCTRL_2              ((uint32_t)0x1f8U)
 
 /* PHY related */
 #define DDR_PHYA_MASTER0_CALBUSY		0x4038165C
@@ -210,17 +237,88 @@
 #define UCT_WRITE_PROT_SHADOW_MASK              0x1U
 #define DDR_PHYA_DCTWRITEPROT			0x4038040C
 #define DDR_PHYA_APBONLY_UCTWRITEONLYSHADOW	0x40380410
-#define OFFSET_DDRC_RFSHCTL3			(uint32_t)0x60U
+#define OFFSET_DDRC_RFSHCTL3			((uint32_t)0x60U)
 #define DDR_PHYA_UCCLKHCLKENABLES		0x40380BEC
 #define UCT_WRITE_PROT_SHADOW_ACK		0x0U
+#define TXDQDLY_COARSE				6
+#define DDRPHY_PIPE_DFI_MISC			1U
+#define ARDPTR_INITVAL_ADDR			0x40381494
+
+#define CDD_CHA_RR_1_0    0x403b004d
+#define CDD_CHA_RR_0_1    0x403b004c
+#define CDD_CHA_RW_1_1    0x403b0051
+#define CDD_CHA_RW_1_0    0x403b0050
+#define CDD_CHA_RW_0_1    0x403b0055
+#define CDD_CHA_RW_0_0    0x403b0054
+#define CDD_CHA_WR_1_1    0x403b0059
+#define CDD_CHA_WR_1_0    0x403b0058
+#define CDD_CHA_WR_0_1    0x403b005d
+#define CDD_CHA_WR_0_0    0x403b005c
+#define CDD_CHA_WW_1_0    0x403b0061
+#define CDD_CHA_WW_0_1    0x403b0060
+
+#define CDD_CHB_RR_1_0    0x403b00b1
+#define CDD_CHB_RR_0_1    0x403b00b4
+#define CDD_CHB_RW_1_1    0x403b00b5
+#define CDD_CHB_RW_1_0    0x403b00b8
+#define CDD_CHB_RW_0_1    0x403b00b9
+#define CDD_CHB_RW_0_0    0x403b00bc
+#define CDD_CHB_WR_1_1    0x403b00bd
+#define CDD_CHB_WR_1_0    0x403b00c0
+#define CDD_CHB_WR_0_1    0x403b00c1
+#define CDD_CHB_WR_0_0    0x403b00c4
+#define CDD_CHB_WW_1_0    0x403b00c5
+#define CDD_CHB_WW_0_1    0x403b00c8
+
+#define CDD_CHA_RR_1_0_DDR3   0x403b0059
+#define CDD_CHA_RR_0_1_DDR3   0x403b0060
+#define CDD_CHA_RW_1_1_DDR3   0x403b008d
+#define CDD_CHA_RW_1_0_DDR3   0x403b0090
+#define CDD_CHA_RW_0_1_DDR3   0x403b0095
+#define CDD_CHA_RW_0_0_DDR3   0x403b0098
+#define CDD_CHA_WR_1_1_DDR3   0x403b00ad
+#define CDD_CHA_WR_1_0_DDR3   0x403b00b0
+#define CDD_CHA_WR_0_1_DDR3   0x403b00b5
+#define CDD_CHA_WR_0_0_DDR3   0x403b00b8
+#define CDD_CHA_WW_1_0_DDR3   0x403b0071
+#define CDD_CHA_WW_0_1_DDR3   0x403b0078
+
+#define DBYTE0_TXDQSDLYTG0_U0 0x40394b4c
+#define DBYTE0_TXDQSDLYTG0_U1 0x40394b50
+#define DBYTE1_TXDQSDLYTG0_U0 0x40396b4c
+#define DBYTE1_TXDQSDLYTG0_U1 0x40396b50
+#define DBYTE2_TXDQSDLYTG0_U0 0x40398b4c
+#define DBYTE2_TXDQSDLYTG0_U1 0x40398b50
+#define DBYTE3_TXDQSDLYTG0_U0 0x4039ab4c
+#define DBYTE3_TXDQSDLYTG0_U1 0x4039ab50
+
+#define DBYTE0_TXDQSDLYTG1_U0 0x40394b6c
+#define DBYTE0_TXDQSDLYTG1_U1 0x40394b70
+#define DBYTE1_TXDQSDLYTG1_U0 0x40396b6c
+#define DBYTE1_TXDQSDLYTG1_U1 0x40396b70
+#define DBYTE2_TXDQSDLYTG1_U0 0x40398b6c
+#define DBYTE2_TXDQSDLYTG1_U1 0x40398b70
+#define DBYTE3_TXDQSDLYTG1_U0 0x4039ab6c
+#define DBYTE3_TXDQSDLYTG1_U1 0x4039ab70
+
+#define VREF_CA_A0 0x403b0095
+#define VREF_CA_A1 0x403b0098
+#define VREF_CA_B0 0x403b00fc
+#define VREF_CA_B1 0x403b00fd
+
+#define VREF_DQ_A0 0x403b0099
+#define VREF_DQ_A1 0x403b009c
+#define VREF_DQ_B0 0x403b0100
+#define VREF_DQ_B1 0x403b0101
 
 #define SHIFT_BIT(nr)             (((uint32_t)0x1U) << (nr))
 #define UCCLKEN_MASK              SHIFT_BIT(0)
 #define HCLKEN_MASK               SHIFT_BIT(1)
-#define OFFSET_DDRC_INIT0         (uint32_t)0xd0U
+#define OFFSET_DDRC_INIT0         ((uint32_t)0xd0U)
 
 #define STORE_CSR_MASK            SHIFT_BIT(0)
 #define INIT_MEM_MASK             SHIFT_BIT(1)
+#define ADJUST_DDRC_MASK          SHIFT_BIT(2)
 #define SCRUB_EN_MASK             SHIFT_BIT(0)
 #define SCRUB_BUSY_MASK           SHIFT_BIT(0)
 #define SELFREF_SW_MASK           SHIFT_BIT(5)
@@ -244,10 +342,10 @@
 /* Reset Generation Module */
 #define MC_RGM_PRST_0             0x40078040
 #ifndef MC_CGM5_BASE_ADDR
-#define MC_CGM5_BASE_ADDR         (uint32_t)0x40068000U
+#define MC_CGM5_BASE_ADDR         ((uint32_t)0x40068000U)
 #endif
-#define OFFSET_MUX_0_CSS          (uint32_t)0x304U
-#define OFFSET_MUX_0_CSC          (uint32_t)0x300U
+#define OFFSET_MUX_0_CSS          ((uint32_t)0x304U)
+#define OFFSET_MUX_0_CSC          ((uint32_t)0x300U)
 #define FIRC_CLK_SRC              0x0U
 #define DDR_PHI0_PLL              0x24U
 
@@ -270,6 +368,23 @@
 /* ERR050760 related defines */
 #define REQUIRED_MRSTAT_READS 0x2U
 
+/* Compute the number of elements in the given array */
+#define ARRAY_SIZE(a) (sizeof(a) / sizeof((a)[0]))
+
+struct cdd_type {
+	uint8_t rr;
+	uint8_t rw;
+	uint8_t wr;
+	uint8_t ww;
+};
+
+struct space_timing_params {
+	struct cdd_type cdd;
+	uint8_t vref_ca;
+	uint8_t vref_dq;
+	uint16_t tphy_wrdata_delay;
+};
+
 #if (ERRATA_S32_050543 == 1)
 extern uint8_t polling_needed;
 #endif
@@ -299,6 +414,21 @@ uint32_t read_lpddr4_mr(uint8_t mr_index);
  */
 uint32_t write_lpddr4_mr(uint8_t mr_index, uint8_t mr_data);
 
+/* Modify bitfield value with delta, given bitfield position and mask */
+bool update_bf(uint32_t *v, uint8_t pos, uint32_t mask, int32_t delta);
+
+/* Read Critical Delay Differences from message block and store max values */
+void read_cdds(void);
+
+/* Read trained VrefCA from message block and store average value */
+void read_vref_ca(void);
+
+/* Read trained VrefDQ from message block and store average value */
+void read_vref_dq(void);
+
+/* Calculate DFITMG1.dfi_t_wrdata_delay */
+void compute_tphy_wrdata_delay(void);
+
 #if (ERRATA_S32_050543 == 1)
 /* Read Temperature Update Flag from lpddr4 MR4 register. */
 uint8_t read_tuf(void);
@@ -323,8 +453,6 @@ uint32_t enable_derating_temp_errata(void);
  */
 uint32_t poll_derating_temp_errata(bool traffic_halted);
 
-/* Modify bitfield value with delta, given bitfield position and mask */
-bool update_bf(uint32_t *v, uint8_t pos, uint32_t mask, int32_t delta);
 #endif
 
 #endif /* DDR_UTILS_H_ */
-- 
2.17.1

