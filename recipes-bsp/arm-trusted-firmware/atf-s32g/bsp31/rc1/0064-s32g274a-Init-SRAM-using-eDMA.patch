From f981ec543301884493b372d86425eca644128514 Mon Sep 17 00:00:00 2001
From: Dan Nica <dan.nica@nxp.com>
Date: Thu, 30 Jan 2020 14:48:44 +0200
Subject: [PATCH 064/269] s32g274a: Init SRAM using eDMA

Issue: ALB-4568
Upstream-Status: Pending 

Signed-off-by: Dan Nica <dan.nica@nxp.com>
Signed-off-by: Zhantao Tang <zhantao.tang@windriver.com>
---
 plat/s32g/include/s32g274a_edma.h |  27 +++++
 plat/s32g/s32g_lowlevel_bl2.S     |   6 +-
 plat/s32g/s32g_lowlevel_common.S  | 189 +++++++++++++++++++++++++-----
 3 files changed, 191 insertions(+), 31 deletions(-)
 create mode 100644 plat/s32g/include/s32g274a_edma.h

diff --git a/plat/s32g/include/s32g274a_edma.h b/plat/s32g/include/s32g274a_edma.h
new file mode 100644
index 000000000..b0e877c39
--- /dev/null
+++ b/plat/s32g/include/s32g274a_edma.h
@@ -0,0 +1,27 @@
+/*
+ * Copyright 2020 NXP
+ *
+ * SPDX-License-Identifier:	GPL-2.0+
+ */
+
+#ifndef S32G274A_EDMA_H
+#define S32G274A_EDMA_H
+
+#define EDMA0_MP			(0x40144000)
+#define EDMA0_TCD			(EDMA0_MP + 0x4000)
+#define DMA_CHANNEL_1			(1)
+
+#define EDMA0_MP_ES			(EDMA0_MP + 0x4)
+#define EDMA0_CHn_CSR(ch)		(EDMA0_TCD + 0x1000 * (ch))
+#define EDMA0_CHn_ES(ch)		(EDMA0_TCD + 0x1000 * (ch) + 0x04)
+#define EDMA0_TCDn_SADDR(ch)		(EDMA0_TCD + 0x1000 * (ch) + 0x20)
+#define EDMA0_TCDn_SOFF(ch)		(EDMA0_TCD + 0x1000 * (ch) + 0x24)
+#define EDMA0_TCDn_ATTR(ch)		(EDMA0_TCD + 0x1000 * (ch) + 0x26)
+#define EDMA0_TCDn_NBYTES_MLOFFNO(ch)	(EDMA0_TCD + 0x1000 * (ch) + 0x28)
+#define EDMA0_TCDn_DADDR(ch)		(EDMA0_TCD + 0x1000 * (ch) + 0x30)
+#define EDMA0_TCDn_DOFF(ch)		(EDMA0_TCD + 0x1000 * (ch) + 0x34)
+#define EDMA0_TCDn_CITER_ELINKNO(ch)	(EDMA0_TCD + 0x1000 * (ch) + 0x36)
+#define EDMA0_TCDn_CSR(ch)		(EDMA0_TCD + 0x1000 * (ch) + 0x3c)
+#define EDMA0_TCDn_BITER_ELINKNO(ch)	(EDMA0_TCD + 0x1000 * (ch) + 0x3e)
+
+#endif /* S32G274A_EDMA_H */
diff --git a/plat/s32g/s32g_lowlevel_bl2.S b/plat/s32g/s32g_lowlevel_bl2.S
index be8efe07e..ccf2d84bb 100644
--- a/plat/s32g/s32g_lowlevel_bl2.S
+++ b/plat/s32g/s32g_lowlevel_bl2.S
@@ -1,5 +1,5 @@
 /*
- * Copyright 2019 NXP
+ * Copyright 2019-2020 NXP
  *
  * SPDX-License-Identifier: BSD-3-Clause
  */
@@ -10,7 +10,7 @@
 
 .globl platform_mem_init
 .globl plat_reset_handler
-.globl s32g_sram_init
+.globl sram_clr
 .globl plat_secondary_cold_boot_setup
 
 
@@ -46,7 +46,7 @@ func plat_reset_handler
 	ldr	x0,=__STACKS_START__
 	ldr	x1,=__BL2_END__
 	sub	x1, x1, x0
-	bl	s32g_sram_init
+	bl	sram_clr
 
 	mov	x30, x7
 	ret
diff --git a/plat/s32g/s32g_lowlevel_common.S b/plat/s32g/s32g_lowlevel_common.S
index 58d018d5d..4118541e1 100644
--- a/plat/s32g/s32g_lowlevel_common.S
+++ b/plat/s32g/s32g_lowlevel_common.S
@@ -1,5 +1,5 @@
 /*
- * Copyright 2019 NXP
+ * Copyright 2019-2020 NXP
  *
  * SPDX-License-Identifier: BSD-3-Clause
  */
@@ -7,12 +7,13 @@
 #include <asm_macros.S>
 #include <console_macros.S>
 #include "platform_def.h"
+#include "s32g274a_edma.h"
 
 .globl plat_is_my_cpu_primary
 .globl plat_my_core_pos
 .globl plat_core_pos_by_mpidr
-.globl s32g_sram_init
-
+.globl dma_mem_clr
+.globl sram_clr
 
 /* Set the CAIUTC[IsolEn] bit for the primary A53 cluster.
  * This is so cache invalidate operations from the early TF-A boot code
@@ -31,37 +32,155 @@ func s32g_ncore_isol_cluster0
 	ret
 endfunc s32g_ncore_isol_cluster0
 
+/* x0: start address of memory area to clear
+ * x1: size of memory area to clear
+ * x0: return 0 on error or size of memory cleared on success
+ * Clobber list: x0,x9,x12,x13
+ */
 
-/* Quick and dirty (read: 'naive') implementation of U-Boot's dma_mem_clr
- * routine. TODO: We will switch to that one, based on eDMA, as soon as we
- * finish up core clock debugging. Meanwhile, preserve the calling convention.
- *
- * x0: start address of memory to clear
+func dma_mem_clr
+	orr	x12, x0, x1
+	and 	x12, x12, #0x3f
+	cbz 	x12, transfer_size_64bytes
+	and 	x12, x12, #0x7
+	cbz 	x12, transfer_size_8bytes
+	/* Assert that the addresses are aligned on at least a 64bit
+	 * boundary, otherwise the transfer to an unitialized
+	 * sram would fail anyway.
+	 */
+	bl	plat_panic_handler
+
+transfer_size_8bytes:
+	ldr	x9, =EDMA0_TCDn_ATTR(DMA_CHANNEL_1)
+	mov	w12, #0x0303 /* 8bytes transfer size */
+	strh	w12, [x9]
+
+	ldr	x9, =EDMA0_TCDn_DOFF(DMA_CHANNEL_1)
+	mov	w12, #0x0008 /* increment by 8bytes */
+	strh	w12, [x9]
+	b	transfer_size_determined
+
+transfer_size_64bytes:
+	ldr	x9, =EDMA0_TCDn_ATTR(DMA_CHANNEL_1)
+	mov	w12, #0x0606 /* 64bytes transfer size */
+	strh	w12, [x9]
+
+	ldr	x9, =EDMA0_TCDn_DOFF(DMA_CHANNEL_1)
+	mov	w12, #0x0040 /* increment by 64bytes */
+	strh	w12, [x9]
+transfer_size_determined:
+
+	ldr	x9, =EDMA0_TCDn_DADDR(DMA_CHANNEL_1)
+	str 	w0, [x9]
+
+	ldr	x9, =EDMA0_TCDn_SOFF(DMA_CHANNEL_1)
+	strh	wzr, [x9]
+
+	ldr	x9, =EDMA0_TCDn_SADDR(DMA_CHANNEL_1)
+	ldr	x12, =initvar
+	str	w12, [x9]
+
+	ldr	x9, =EDMA0_TCDn_NBYTES_MLOFFNO(DMA_CHANNEL_1)
+	str 	w1, [x9]
+
+	mov	w12, #0x0001
+	ldr	x9, =EDMA0_TCDn_CITER_ELINKNO(DMA_CHANNEL_1)
+	strh	w12, [x9]
+	ldr	x9, =EDMA0_TCDn_BITER_ELINKNO(DMA_CHANNEL_1)
+	strh	w12, [x9]
+
+	ldr	x9, =EDMA0_TCDn_CSR(DMA_CHANNEL_1)
+	mov	w12, #0x0001
+	strb	w12, [x9]
+
+check_status:
+	/* Check error status */
+	ldr	x9, =EDMA0_MP_ES
+	ldr	w12, [x9]
+	and	w12, w12, #0x80000000
+	movz	w13, #0x8000, lsl #16
+	sub	w12, w12, w13
+	cbz	w12, transfer_error
+
+	/* Check transfer done */
+	ldr	x9, =EDMA0_CHn_CSR(DMA_CHANNEL_1)
+	ldr 	w12, [x9]
+	and 	w12, w12, #0x40000000
+	movz	w13, #0x4000, lsl #16
+	sub	w12, w12, w13
+	cbnz	w12, check_status
+
+	/* Clear EDMA0_CHn_CSR:DONE bit */
+	ldr	x9, =EDMA0_CHn_CSR(DMA_CHANNEL_1)
+	movz	w12, #0x4000, lsl #16
+	str	w12, [x9]
+
+	mov	x0, x1
+	ret
+
+transfer_error:
+	ldr	x9, =EDMA0_CHn_ES(DMA_CHANNEL_1)
+	movz	w10, #0x8000, lsl #16
+	str	w10, [x9]
+
+	mov	x0, #0x0
+	ret
+endfunc dma_mem_clr
+
+/* x0: start address of memory area to clear
  * x1: size of memory area to clear
- *
- * Clobber list: x0,x1,x9,x11
- *
- * NOTE/FIXME: Memory area MUST be 8-byte aligned. We are not making any checks.
+ * x0: return 0 on error or size of memory cleared on success
+ * Clobber list: x0,x1,x10,x11,x15
  */
-func s32g_sram_init
-	mov	x9, x30
 
+func sram_clr
 	add	x1, x0, x1
-init:
-	str	xzr, [x0]
-	ldr	x11, [x0], #8
-	cmp	x11, xzr
-	bne	assert_loop
-	cmp	x0, x1
-	blt	init
-
-	mov x30, x9
-	ret
-assert_loop:
-	b	.
-	no_ret	plat_panic_handler
-endfunc s32g_sram_init
 
+	/* save registers that are clobbered by dma_mem_clr */
+	mov	x15, x30
+	mov	x10, x0
+	mov	x11, x1
+
+	/* If the start address is not aligned to 64bytes, the ideal
+	 * transfer size for edma, perform a suboptimal edma transfer
+	 * on the region until the first 64byte boundary.
+	 */
+	and	x1, x10, #0x3f
+	cbz	x1, unaligned_start_done
+	mov 	x1, x10, lsr #6
+	mov 	x1, x1, lsl #6
+	add 	x1, x1, #0x40
+	mov	x10, x1
+	sub	x1, x1, x0
+	bl	dma_mem_clr
+unaligned_start_done:
+
+	/* Forcefully align the end address on a 64byte boundary
+	 * and request an edma transfer.
+	 */
+	mov	x0, x10
+	mov 	x1, x11
+	mov 	x1, x1, lsr #6
+	mov 	x1, x1, lsl #6
+	sub 	x1, x1, x0
+	bl	dma_mem_clr
+
+	/* Perform another suboptimal edma transfer if there is an
+	 * unaligned leftover region at the end after we forcefully
+	 * aligned the address above.
+	 */
+	mov	x0, x11
+	mov 	x0, x0, lsr #6
+	mov 	x0, x0, lsl #6
+	mov 	x1, x11
+	sub 	x1, x1, x0
+	cbz 	x1, unaligned_end_done
+	bl	dma_mem_clr
+unaligned_end_done:
+
+	mov	x30, x15
+	ret
+endfunc sram_clr
 
 /* Clobber list: x0,x1,x7,x8
  */
@@ -108,3 +227,17 @@ func plat_core_pos_by_mpidr
 	mov	x30, x7
 	ret
 endfunc plat_core_pos_by_mpidr
+
+/* Used by 'dma_mem_clr' and required to be aligned to
+ * edma's maximum transfer size, which is 64bytes.
+ */
+.align 6
+initvar:
+	.quad 0x0
+	.quad 0x0
+	.quad 0x0
+	.quad 0x0
+	.quad 0x0
+	.quad 0x0
+	.quad 0x0
+	.quad 0x0
-- 
2.17.1

